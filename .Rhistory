dat <- read.csv("dat1.csv")
library("MASS")
library("leaps")
i.	lm0<-lm(marathon~1, data= dat1)
ii.	summary(lm0)
iii.	upper <- as.formula(paste("marathon~",paste(names(dat1)[1:7], collapse="+")))
iv.	step(lm0, scope=upper, direction="forward",trace=1)
v.	best<-leaps(dat1[,1:7], dat1[,8], method="Cp", nbest=2, names=names(dat1)[1:7])
vi.	data.frame(size=best$size,Cp=best$Cp,best$which)
lm0<-lm(marathon~1, data= dat1)
summary(lm0)
upper <- as.formula(paste("marathon~",paste(names(dat1)[1:7], collapse="+")))
step(lm0, scope=upper, direction="forward",trace=1)
best<-leaps(dat1[,1:7], dat1[,8], method="Cp", nbest=2, names=names(dat1)[1:7])
data.frame(size=best$size,Cp=best$Cp,best$which)
library("rgl")
dat = data.frame{x1 = (2.23, 2.57, 387, 3.10, 3.39, 2.83, 3.02, 2.14, 3.04, 3.26, 3.39, 2.35, 2.76, 3.90, 3.16), }
var(c(12.37, 12.66, 12, 11.93, 11.06, 13.03, 13.13, 11.44, 12.86, 10.84, 11.20, 11.56, 10.83, 12.53, 12.46))
avg(c(12.37, 12.66, 12, 11.93, 11.06, 13.03, 13.13, 11.44, 12.86, 10.84, 11.20, 11.56, 10.83, 12.53, 12.46))
average(c(12.37, 12.66, 12, 11.93, 11.06, 13.03, 13.13, 11.44, 12.86, 10.84, 11.20, 11.56, 10.83, 12.53, 12.46))
mean(c(12.37, 12.66, 12, 11.93, 11.06, 13.03, 13.13, 11.44, 12.86, 10.84, 11.20, 11.56, 10.83, 12.53, 12.46))
x1 = c(12.37, 12.66, 12, 11.93, 11.06, 13.03, 13.13, 11.44, 12.86, 10.84, 11.20, 11.56, 10.83, 12.53, 12.46)
x2
x1
x2 = x1-11.99333
x2
x3 = x2^2
x3
sst = sum(x3)
sst
dat = data.frame(x = c(21, 24, 25, 26, 28, 31, 33, 34, 35, 36, 43, 49, 51, 55, 25, 29, 43, 44, 46, 51, 55, 56, 58), y = c(1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0))
dat
dat = data.frame(x = c(21, 24, 25, 26, 28, 31, 33, 34, 35, 37, 43, 49, 51, 55, 25, 29, 43, 44, 46, 46, 51, 55, 56, 58), y = c(1,1,1,1,1,1,1,1,1,1,1,1,1,1, 0,0,0,0,0,0,0,0,0,0))
dat
install.packages("glm")
lm1 <- glm(y~x, dat)
lm1 <- glm(y~x, dat, family = binary)
lm1 <- glm(y~x, dat, family = "binary")
lm1 <- glm(y~x, dat, family = binomial(link = "logit"))
summary(lm1)
predict(glm, type = "response")
predict(lm1, type = "response")
plot(dat$y, predict(lm1, type = "response"))
confint(lm1, x1 = 10, level = 0.95)
confint(lm1, x1 = 10, level = 0.95, type="response")
confint(lm1, level = 0.95, type="response")
confint(lm1, level = 0.95)
confint(lm1, 1, level = 0.95)
confint(lm1, level = 0.95)
a = exp(3.81944+(-0.1831181*10))
a/(1+a)
a = exp(3.81944+(-0.00869711*10))
a/(1+a)
predict(lm1,newdata=data.frame(x=10))
predict(lm1,newdata=data.frame(x=10), type="response")
pred = predict(lm1, type = "response")
ps = c(.1, .2, .3, .4, .5, .6, .7, .8, .9)
rate = c(0,0,0,0,0,0,0,0,0)
for (p in ps)
class = pred > p
class
ps
class = pred > .7
pred
class
for (p in ps)
class = pred > p; rate = sum(class != dat$y)
rate
rate = c(0,0,0,0,0,0,0,0,0)
for (p in ps)
class = pred > p; rate = sum(class != dat$y)
indexes = c(1,2,3,4,5,6,7,8,9)
for (i in indexes)
class = pred > p(i); rate(i) = sum(class != dat$y)
for (i in indexes)
class = pred > p[i]; rate[i] = sum(class != dat$y)
rate
class
i
p[i]
p[8]
p
for (i in indexes)
class = pred > ps[i]; rate[i] = sum(class != dat$y)
rate
ps[2]
class = pred > .2
class
class != dat$y
sum(class != dat$y)
rate[2] = 10
rate
for (i in indexes)
class = pred > ps[i]; test = class != dat$y; rate[i] <- sum(test);
rate
rate[2]
rate[3]
size(rate)
class = pred>.3
rate[3] = sum(class != dat$y)
rate[3]
class = pred>.4
rate[4] = sum(class != dat$y)
class = pred>.5
rate[5] = sum(class != dat$y)
class = pred>.6
rate[6] = sum(class != dat$y)
class = pred>.7
rate[7] = sum(class != dat$y)
class = pred>.8
rate[8] = sum(class != dat$y)
class = pred>.9
rate[9] = sum(class != dat$y)
rate
sum(dat$y)
class = pred>.6
class
dat$y
dat$y = 1
dat = data.frame(x = c(21, 24, 25, 26, 28, 31, 33, 34, 35, 37, 43, 49, 51, 55, 25, 29, 43, 44, 46, 46, 51, 55, 56, 58), y = c(1,1,1,1,1,1,1,1,1,1,1,1,1,1, 0,0,0,0,0,0,0,0,0,0))
a = dat$y == 1
a
class
install.packages("pROC")
library(pROC)
plot.roc(dat$y, lm1$fitted.values,xlab="Specificity",ylab="Sensitivity")
lm1$fitted.values
lm1$fitted.values*class
lm1$fitted.values[class]
lm1$fitted.values[1-class]
class
missClass = 1-class
missClass
lm1$fitted.values[class]
lm1$fitted.values[missClass]
missClass = class!=TRUE
missClass
lm1$fitted.values[class]
lm1$fitted.values[missClass]
missClass = dat$y!=1
lm1$fitted.values[dat$y]
lm1$fitted.values[missClass]
class1 = dat$y ==TRUE
lm1$fitted.values[class1]
lm1$fitted.values[missClass]
sum = 0
for (ii in =c(1,2,3,4,5,6,7,8,9,10))
for (ii in c(1,2,3,4,5,6,7,8,9,10))
sum = sum + 0
a = lm1$fitted.values[class1]
b = lm1$fitted.values[missClass]
sum1 = 0
ties = 0
for (p in b) {
sum1 = sum1 + sum(a < b)
ties = ties + sum(a==b)
}
warnings()
ties = ties + sum(p==b)
a = lm1$fitted.values[class1]
b = lm1$fitted.values[missClass]
sum1 = 0
ties = 0
for (p in b) {
sum1 = sum1 + sum(p < b)
ties = ties + sum(p==b)
}
sum1
ties
a
b
14*10
(sum1 + .5*ties)/140
a = lm1$fitted.values[class1]
b = lm1$fitted.values[missClass]
sum1 = 0
ties = 0
for (p in b) {
sum1 = sum1 + sum(p > b)
ties = ties + sum(p==b)
}
(sum1 + .5*ties)/140
a = lm1$fitted.values[class1]
b = lm1$fitted.values[missClass]
sum1 = 0
ties = 0
for (p in b) {
sum1 = sum1 + sum(p > a)
ties = ties + sum(p==b)
}
(sum1 + .5*ties)/140
dat$y
a = lm1$fitted.values[dat$y]
b = lm1$fitted.values[dat$y!=1]
a
b
a = lm1$fitted.values[dat$y==1]
b = lm1$fitted.values[dat$y!=1]
a
b
sum(b[1]>a)
b[1]>a
a = lm1$fitted.values[dat$y==1]
b = lm1$fitted.values[dat$y!=1]
sum1 = 0
ties = 0
for (p in b) {
sum1 = sum1 + sum(p > a)
ties = ties + sum(p==b)
}
(sum1 + .5*ties)/140
sum1
a = lm1$fitted.values[dat$y==1]
b = lm1$fitted.values[dat$y!=1]
sum1 = 0
ties = 0
for (p in b) {
sum1 = sum1 + sum(p < a)
ties = ties + sum(p==b)
}
(sum1 + .5*ties)/140
#library(glmnet)
library(leaps)
library(bestglm)
data <- read.csv("Huazhen_Joel_Ethan_Updated.csv")
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6))
# create new interaction variables for consistency (Per Joel)
df$consistent1<-df$ordtyr2*df$ordlyr2
df$consistent2<-df$consistent1*df$ord2ago
df$consistent3<-df$consistent2*df$ord3ago
# binary variables for orders
df$ordtb<-ifelse(df$ordtyr2>0,1,0)
df$ordlb<-ifelse(df$ordlyr2>0,1,0)
df$ord2b<-ifelse(df$ord2ago>0,1,0)
df$ord3b<-ifelse(df$ord3ago>0,1,0)
# binary consistency variables for orders
df$cons1b<-df$ordtb*df$ordlb
df$cons2b<-df$cons1b*df$ord2b
df$cons3b<-df$cons2b*df$ord3b
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
library(leaps)
library(bestglm)
library(leaps)
data <- read.csv("Huazhen_Joel_Ethan_Updated.csv")
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6))
# create new interaction variables for consistency (Per Joel)
df$consistent1<-df$ordtyr2*df$ordlyr2
df$consistent2<-df$consistent1*df$ord2ago
df$consistent3<-df$consistent2*df$ord3ago
# binary variables for orders
df$ordtb<-ifelse(df$ordtyr2>0,1,0)
df$ordlb<-ifelse(df$ordlyr2>0,1,0)
df$ord2b<-ifelse(df$ord2ago>0,1,0)
df$ord3b<-ifelse(df$ord3ago>0,1,0)
# binary consistency variables for orders
df$cons1b<-df$ordtb*df$ordlb
df$cons2b<-df$cons1b*df$ord2b
df$cons3b<-df$cons2b*df$ord3b
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
data <- read.csv("Huazhen_Joel_Ethan_Updated.csv")
# Generate regression data set
regDat = data[data$targdol > 0,]
setwd("~/Documents/IEMS462Project")
library(leaps)
#library(bestglm)
data <- read.csv("Huazhen_Joel_Ethan_Updated.csv")
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6))
# create new interaction variables for consistency (Per Joel)
df$consistent1<-df$ordtyr2*df$ordlyr2
df$consistent2<-df$consistent1*df$ord2ago
df$consistent3<-df$consistent2*df$ord3ago
# binary variables for orders
df$ordtb<-ifelse(df$ordtyr2>0,1,0)
df$ordlb<-ifelse(df$ordlyr2>0,1,0)
df$ord2b<-ifelse(df$ord2ago>0,1,0)
df$ord3b<-ifelse(df$ord3ago>0,1,0)
# binary consistency variables for orders
df$cons1b<-df$ordtb*df$ordlb
df$cons2b<-df$cons1b*df$ord2b
df$cons3b<-df$cons2b*df$ord3b
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
x<-train[,-1]
y<-train[,1]
test<-df[which(df$train!=1),]
x_test<-test[,-1]
y_test<-test[,1]
x_test<-sapply(x_test,as.numeric)
x<-sapply(x,as.numeric)
# str(x)
# fit the model using LASSO regression (this takes a minute or two)
cvfit<-cv.glmnet(x,y)
plot(cvfit)
library(glmnet)
x<-train[,-1]
y<-train[,1]
test<-df[which(df$train!=1),]
x_test<-test[,-1]
y_test<-test[,1]
x_test<-sapply(x_test,as.numeric)
x<-sapply(x,as.numeric)
# str(x)
# fit the model using LASSO regression (this takes a minute or two)
cvfit<-cv.glmnet(x,y)
plot(cvfit)
coef(cvfit, s= cvfit$lambda.min)
newFit = lm(targdol ~ slstyr + slslyr + sls2ago + slshist + ordhist + falord + consistent3 + ordlb + ord3b + cons2b + cons3b, data = train)
summary(newFit)
View(df)
newData = polym(df$slstyr, df$slslyr, df$sls2ago, df$sls3ago, df$slshist, degree = 5, raw = TRUE)
tryInteractions = data.frame(df, newData)
summary(tryInteractions)
tryNewCvfit<-cv.glmnet(tryInteractions[,-1],tryInteractions[,1])
tryInteractions = as.numeric(tryInteractions)
tryInteractions = sapply(tryInteractions,as.numeric)
tryNewCvfit<-cv.glmnet(tryInteractions[,-1],tryInteractions[,1])
coef(tryNewCvfit)
coef(tryNewCvfit, s = tryNewCvfit$lambda.min)
corr(df)
cor(df)
max(cor(df))
max(cor(df)-eye(28))
max(cor(df)-I(28))
max(cor(df)-diag(28))
which(df, 0.9983909)
which(df= 0.9983909)
which(max(cor(df)-diag(28)))
which(df== 0.9983909)
which(df ==max(cor(df)-diag(28)))
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6))
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6))
# create new interaction variables for consistency (Per Joel)
df$consistent1<-df$ordtyr2*df$ordlyr2
df$consistent2<-df$consistent1*df$ord2ago
df$consistent3<-df$consistent2*df$ord3ago
# binary variables for orders
df$ordtb<-ifelse(df$ordtyr2>0,1,0)
df$ordlb<-ifelse(df$ordlyr2>0,1,0)
df$ord2b<-ifelse(df$ord2ago>0,1,0)
df$ord3b<-ifelse(df$ord3ago>0,1,0)
# binary consistency variables for orders
df$cons1b<-df$ordtb*df$ordlb
df$cons2b<-df$cons1b*df$ord2b
df$cons3b<-df$cons2b*df$ord3b
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6, recency_numeric, recency_factor))
# create new interaction variables for consistency (Per Joel)
df$consistent1<-df$ordtyr2*df$ordlyr2
df$consistent2<-df$consistent1*df$ord2ago
df$consistent3<-df$consistent2*df$ord3ago
# binary variables for orders
df$ordtb<-ifelse(df$ordtyr2>0,1,0)
df$ordlb<-ifelse(df$ordlyr2>0,1,0)
df$ord2b<-ifelse(df$ord2ago>0,1,0)
df$ord3b<-ifelse(df$ord3ago>0,1,0)
# binary consistency variables for orders
df$cons1b<-df$ordtb*df$ordlb
df$cons2b<-df$cons1b*df$ord2b
df$cons3b<-df$cons2b*df$ord3b
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
# Generate regression data set
regDat = data[data$targdol > 0,]
# remove extraneous variables (Per Joel)
df<-within(regDat,rm(dm_ad,dm_lp,datelp6,X.1,X,ordtyr,ordlyr,datead6))
# create new interaction variables for consistency (Per Joel)
df$consistent1<-df$ordtyr2*df$ordlyr2
df$consistent2<-df$consistent1*df$ord2ago
df$consistent3<-df$consistent2*df$ord3ago
# binary variables for orders
df$ordtb<-ifelse(df$ordtyr2>0,1,0)
df$ordlb<-ifelse(df$ordlyr2>0,1,0)
df$ord2b<-ifelse(df$ord2ago>0,1,0)
df$ord3b<-ifelse(df$ord3ago>0,1,0)
# binary consistency variables for orders
df$cons1b<-df$ordtb*df$ordlb
df$cons2b<-df$cons1b*df$ord2b
df$cons3b<-df$cons2b*df$ord3b
# Define data sets removing sprord and train because sprord is correlated with falord
train<-df[which(df$train==1),]
train <- data.frame(train[,c(-11,-12)])
test<-df[which(df$train!=1),]
test <- data.frame(test[,c(-11,-12)])
fit1 = lm(targdol~., data = train)
summary(fit1)
#step(fit1,direction="backward")
stepReg <- step(fit1,direction="both")
#fit2 = lm(targdol~1, train)
#summary(fit2)
#biggest=formula(lm(targdol~.,data=train))
#step(fit2,direction="forward",scope=biggest)
#step(fit2,direction="both",scope=biggest)
summary(stepReg)
plot(stepReg)
